# Context Engineering - Language Agnostic Guide

## ðŸŽ¯ Core Principles (Language Independent)

Context Engineering is **completely language-agnostic**. The principles apply to any programming language or system.

### Universal Concepts

1. **Tool Definition** - Clearly specify what a tool does
   ```
   Name: "analyze_code"
   Description: "Analyze code for complexity and issues"
   Parameters: [
     { name: "code", type: "string", required: true },
     { name: "language", type: "string", required: true }
   ]
   Output: { complexity, issues, suggestions }
   ```

2. **Feedback Loop** - Track and measure results
   ```
   Execute tool â†’ Record metrics â†’ Analyze â†’ Optimize
   ```

3. **Context Management** - Organize information strategically
   ```
   Prioritize information â†’ Respect constraints â†’ Build context
   ```

4. **Iteration** - Improve based on feedback
   ```
   Current context â†’ Execute â†’ Measure â†’ Optimize â†’ Repeat
   ```

---

## ðŸ—‚ï¸ Improved Folder Structure

```
context-engineering-template/
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ PRINCIPLES.md           â† Language-agnostic concepts
â”‚   â”œâ”€â”€ GUIDE.md                â† Framework overview
â”‚   â””â”€â”€ ARCHITECTURE.md         â† Design patterns
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ core/                   â† Language-agnostic interfaces
â”‚   â”‚   â”œâ”€â”€ tool.schema.json    â† Tool definition schema
â”‚   â”‚   â”œâ”€â”€ feedback.schema.json â† Feedback metrics schema
â”‚   â”‚   â””â”€â”€ context.schema.json  â† Context structure schema
â”‚   â”‚
â”‚   â”œâ”€â”€ tools/
â”‚   â”‚   â”œâ”€â”€ examples/           â† Example tool implementations
â”‚   â”‚   â”‚   â”œâ”€â”€ code-analyzer/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ README.md
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ python/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ javascript/
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ go/
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”œâ”€â”€ file-reader/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ README.md
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ python/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ javascript/
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ rust/
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â””â”€â”€ doc-generator/
â”‚   â”‚   â”‚       â”œâ”€â”€ README.md
â”‚   â”‚   â”‚       â”œâ”€â”€ python/
â”‚   â”‚   â”‚       â””â”€â”€ javascript/
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ YOUR_CUSTOM_TOOLS/  â† Your domain-specific tools
â”‚   â”‚
â”‚   â”œâ”€â”€ feedback/               â† Language-agnostic feedback
â”‚   â”‚   â”œâ”€â”€ metrics.schema.json
â”‚   â”‚   â”œâ”€â”€ analyzer.py
â”‚   â”‚   â”œâ”€â”€ analyzer.js
â”‚   â”‚   â””â”€â”€ analyzer.go
â”‚   â”‚
â”‚   â””â”€â”€ context/                â† Language-agnostic context
â”‚       â”œâ”€â”€ builder.py
â”‚       â”œâ”€â”€ builder.js
â”‚       â””â”€â”€ builder.go
â”‚
â”œâ”€â”€ examples/
â”‚   â”œâ”€â”€ python/
â”‚   â”‚   â”œâ”€â”€ basic_workflow.py
â”‚   â”‚   â”œâ”€â”€ advanced_workflow.py
â”‚   â”‚   â””â”€â”€ custom_tools.py
â”‚   â”‚
â”‚   â”œâ”€â”€ javascript/
â”‚   â”‚   â”œâ”€â”€ basic-workflow.ts
â”‚   â”‚   â”œâ”€â”€ advanced-workflow.ts
â”‚   â”‚   â””â”€â”€ custom-tools.ts
â”‚   â”‚
â”‚   â”œâ”€â”€ go/
â”‚   â”‚   â”œâ”€â”€ basic_workflow.go
â”‚   â”‚   â””â”€â”€ custom_tools.go
â”‚   â”‚
â”‚   â””â”€â”€ rust/
â”‚       â””â”€â”€ custom_tools.rs
â”‚
â””â”€â”€ README.md
```

---

## ðŸ“‹ Tool Structure

Each tool should have its own folder with:

### `tools/examples/code-analyzer/README.md`
```markdown
# Code Analyzer Tool

## Description
Analyzes code for complexity, patterns, and potential issues.

## Input Schema
```json
{
  "code": "string (required)",
  "language": "string (required)",
  "analyzeFor": "array (optional)"
}
```

## Output Schema
```json
{
  "success": "boolean",
  "complexity": "string",
  "issues": "array",
  "suggestions": "array"
}
```

## Implementations
- Python: `python/analyze.py`
- JavaScript: `javascript/analyze.ts`
- Go: `go/analyze.go`
```

### `tools/examples/code-analyzer/python/analyze.py`
```python
def analyze_code(code: str, language: str, analyze_for: list = None) -> dict:
    """
    Analyze code for complexity and issues.
    
    Args:
        code: Code snippet to analyze
        language: Programming language
        analyze_for: Optional list of aspects to analyze
    
    Returns:
        dict with complexity, issues, and suggestions
    """
    # Implementation
    return {
        "success": True,
        "complexity": "moderate",
        "issues": [],
        "suggestions": ["Add type hints"]
    }
```

### `tools/examples/code-analyzer/javascript/analyze.ts`
```typescript
interface CodeAnalysisResult {
  success: boolean;
  complexity: 'simple' | 'moderate' | 'complex';
  issues: string[];
  suggestions: string[];
}

export async function analyzeCode(
  code: string,
  language: string,
  analyzeFor?: string[]
): Promise<CodeAnalysisResult> {
  // Implementation
  return {
    success: true,
    complexity: 'moderate',
    issues: [],
    suggestions: ['Add type hints']
  };
}
```

---

## ðŸ”„ Feedback Metrics (Language Agnostic)

All languages should track the same metrics:

```json
{
  "toolName": "string",
  "timestamp": "number (milliseconds since epoch)",
  "success": "boolean",
  "executionTime": "number (milliseconds)",
  "contextTokensUsed": "number",
  "outputQuality": "excellent | good | fair | poor",
  "feedback": "string (optional)"
}
```

### Python Implementation
```python
from dataclasses import dataclass
from datetime import datetime
from typing import Literal

@dataclass
class ExecutionMetrics:
    tool_name: str
    timestamp: float
    success: bool
    execution_time: float  # milliseconds
    context_tokens_used: int
    output_quality: Literal['excellent', 'good', 'fair', 'poor']
    feedback: str = None
```

### Go Implementation
```go
type ExecutionMetrics struct {
    ToolName          string
    Timestamp         int64   // milliseconds since epoch
    Success           bool
    ExecutionTime     float64 // milliseconds
    ContextTokensUsed int
    OutputQuality     string  // "excellent", "good", "fair", "poor"
    Feedback          *string
}
```

---

## ðŸŽ¯ Universal Workflow

Every language implementation should follow:

```
1. BUILD CONTEXT
   â”œâ”€ Gather information from multiple sources
   â”œâ”€ Prioritize by importance (high/medium/low)
   â””â”€ Respect token budget

2. EXECUTE TOOL
   â”œâ”€ Pass context to tool
   â”œâ”€ Tool performs its function
   â””â”€ Tool returns structured result

3. RECORD FEEDBACK
   â”œâ”€ Capture all metrics
   â”œâ”€ Store in standardized format
   â””â”€ Log for analysis

4. ANALYZE RESULTS
   â”œâ”€ Calculate success rate
   â”œâ”€ Identify patterns
   â””â”€ Generate recommendations

5. OPTIMIZE CONTEXT
   â”œâ”€ Apply recommendations
   â”œâ”€ Adjust priorities
   â””â”€ Prepare for next iteration

6. ITERATE
   â””â”€ Repeat with improved context
```

---

## ðŸ› ï¸ Implementing in Your Language

### Step 1: Define Tool Schema

Create `tools/your-tool/README.md`:
```markdown
# Your Tool Name

## Description
What this tool does

## Input Schema
```json
{ "param1": "type", "param2": "type" }
```

## Output Schema
```json
{ "result": "type", "metadata": "type" }
```

## Implementations
- Your language: `your-language/`
```

### Step 2: Create Tool Implementation

In your language of choice:
```pseudocode
FUNCTION execute_tool(name, parameters):
  VALIDATE parameters against schema
  EXECUTE tool logic
  RETURN structured result
```

### Step 3: Record Metrics

All implementations must track:
- Tool name
- Timestamp
- Success/failure
- Execution time
- Tokens used
- Output quality (self-assessed)

### Step 4: Analyze Feedback

Calculate across all executions:
- Success rate: successes / total
- Average execution time
- Quality distribution
- Optimization recommendations

### Step 5: Iterate

Adjust context based on metrics and re-execute.

---

## ðŸ“Š Example: Multi-Language Tool

### Tool: Code Formatter

**Common Interface** (all languages):
```json
{
  "name": "format_code",
  "description": "Format code according to style guide",
  "input": {
    "code": "string",
    "language": "string",
    "style": "string (optional)"
  },
  "output": {
    "success": "boolean",
    "formatted_code": "string",
    "changes": "integer"
  }
}
```

**Python Implementation**:
```python
def format_code(code: str, language: str, style: str = None) -> dict:
    # Use language-specific formatter
    formatted = formatter.format(code)
    return {
        "success": True,
        "formatted_code": formatted,
        "changes": count_changes(code, formatted)
    }
```

**JavaScript Implementation**:
```typescript
async function formatCode(
  code: string, 
  language: string, 
  style?: string
): Promise<FormatResult> {
  const formatted = await formatter.format(code);
  return {
    success: true,
    formatted_code: formatted,
    changes: countChanges(code, formatted)
  };
}
```

**Go Implementation**:
```go
func FormatCode(code, language, style string) map[string]interface{} {
    formatted := formatter.Format(code)
    return map[string]interface{}{
        "success": true,
        "formatted_code": formatted,
        "changes": countChanges(code, formatted),
    }
}
```

---

## ðŸ”— Connecting Across Languages

### Option 1: REST API
Each tool can be a microservice:
```
POST /tools/format_code
Content-Type: application/json

{
  "code": "...",
  "language": "python",
  "style": "pep8"
}
```

### Option 2: Message Queue
Tools communicate via message queue:
```
Queue: tool-requests
Message: {
  "tool": "format_code",
  "parameters": {...},
  "request_id": "uuid"
}

Queue: tool-responses
Message: {
  "request_id": "uuid",
  "result": {...},
  "metrics": {...}
}
```

### Option 3: Shared Data Format
All tools write/read standardized JSON:
```json
{
  "execution_id": "uuid",
  "tool": "format_code",
  "input": {...},
  "output": {...},
  "metrics": {...}
}
```

---

## ðŸ’¡ Key Takeaways

1. **Context Engineering is Universal** - Principles apply to any language
2. **Tools are Language-Specific** - Implement in whatever language fits
3. **Metrics are Standardized** - All tools report same metrics
4. **Workflows are Consistent** - All implementations follow same pattern
5. **Feedback is Shared** - All languages feed into same analysis loop

---

## ðŸ“š Learn More

- `docs/PRINCIPLES.md` - Core concepts
- `docs/GUIDE.md` - Detailed guide
- `examples/` - Language-specific examples
- `src/tools/examples/` - Reference implementations

---

## ðŸŽ¯ Next Steps

1. **Choose Your Language** - Pick where to implement
2. **Define Your Tools** - What problems do you need to solve?
3. **Create Tool Folders** - One folder per tool
4. **Implement** - Write tool in your language
5. **Record Metrics** - Track performance
6. **Analyze & Iterate** - Use feedback to improve

**Context Engineering works in any language!** ðŸš€
